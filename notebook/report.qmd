---
title: "MY472 Summative 2 Project"
author: "Candidate 30552"
format: 
    html:
        embed-resources: true 
---


```{r, include = FALSE} 
knitr::opts_chunk$set(
    echo = FALSE, 
    eval = FALSE,
    message = FALSE, 
    warning = FALSE)

```

```{r basic-setup, eval = TRUE}

# Define function to install or load packages
load_packages <- function(x) {
  y <- x %in% rownames(installed.packages())
  if(any(!y)) install.packages(x[!y])
  invisible(lapply(x, library, character.only=T))
  rm(x, y)
}

# Load required packagess
load_packages(c(
    "tidyverse",
    "here",
    # Database management
    "DBI",
    "RSQLite",
    # APIs and webscraping
    "httr",
    "RSelenium",
    # Text analysis 
    "tm", 
    # Geospatial plots
    "tmap", 
    "sf", 
    "ggrepel", 
    # Random forests
    "parallel",
    "ranger",
    "tidymodels",
    "vip", 
    "rpart", 
    "rpart.plot"
    ))

db <- DBI::dbConnect(RSQLite::SQLite(), here("data/parliament_database.sqlite"))


```



```{r functions, eval = TRUE}

db_table_check <- function(database, table){
  
  rows <- dbGetQuery(database, paste0("SELECT COUNT(1) FROM ", table))
  cols <- dbListFields(database, table)
  cols_n <- length(cols)
  
  result = list(
    n_rows = rows[[1]],
    n_cols = cols_n,
    col_names = cols)

  return(result)
}

# Define function to print loop progress 

progress_perc <- function(num_done, total, additional_message = ""){
    cat("\r", paste0(additional_message, " ", round(num_done/total*100), "% "))
}

replace_null_with_na <- function(x) {
  if (is.list(x)) { # Checks for whether the item is a sublist 
    lapply(x, replace_null_with_na) # if it is, apply the function for each of the elements within the sublist
  } else { # If it isn't, simply apply the main function
    ifelse(is.null(x) || x == "null", "NA", x) 
  }
}


```


# Introduciton 

# Data 



To store the data I collect, I will use a local relational database. This will improve the efficiency of the storage because... It will also allow me to query only the variables I need for anlausis 

I draw on 4 endpoint from parlimanet's API to construct four three tables that I write out to database.

1. Oral questions 
2. Members
3. Constituencies 
4. Elections

Tables: 

1. oral_questions
2. mps
3. constituencies (containing election results)

I then will create an additional table with the results of the measurmeent I use to classify questions. 

4. question_topics 


## Parliament API 

First, I scraped all questions availble from the written and oral endpoints. Both endpoints only return up to 100 questions with one request. However, you can skip responses. Therefore, you can retrieve all questions by looping through... 

These reponses do not return the full text of each question, so I use these responses as a sampling frame 

```{r pull-oral-questions}



get_qs <- function(endpoint_url, n_skip = 0) {
  url <- paste0(
    endpoint_url,
    "?parameters.skip=",
    n_skip,
    "&parameters.take=100")

  response <-
    GET(url) %>%
    content("parsed")

  return(response)
}

# Define functions to pull all questions

pull_all_oral_qs <- function(endpoint_url){

  # Calculate how many questions are in the end point
  n_resp <- GET(paste0(endpoint_url, "?parameters.take=1")) %>%
    content("parsed")
  n <- n_resp$PagingInfo$GlobalTotal

  # Questions can be pulled in batches of 100,
  # calculate how many time we will have to pull
  n_loops <- ceiling(n / 100)

  print(paste0("Oral Qs done at ", Sys.time()))

  for (i in 1:n_loops) {

    n_skip <- (i - 1) * 100 # Skip however many 100s the loop has run

    if (i == 1) { # On first iteration, make new list

      response <- get_qs(endpoint_url, n_skip)
      response <- response$Response

    } else { # On all other iterations, append to existing list

      response_new <- get_qs(endpoint_url, n_skip)
      response_new <- response_new$Response
      response <- c(response, response_new) # Merge responses

    }

    print(paste0(i, " of ", n_loops, " done.")) # Print progress message
    Sys.sleep(1) # Sleep to avoid hammering the API

  }

  print(paste0("Oral Qs done at ", Sys.time()))
  return(response)
}

## APPLY FUNCTIONS

oral_questions <- pull_all_oral_qs(
  "https://oralquestionsandmotions-api.parliament.uk/oralquestions/list")

saveRDS(oral_questions, "data/oral_questions.RDS")

```


```{r clean-oral-questions}

oral_questions <- readRDS("data/oral_questions.RDS")

### Convert elements of the list into tables ###

# Members asking

for (i in seq_along(oral_questions)) {
  if (i == 1) {

    # Extract asking member information
    member_df <- data.frame(lapply(
      oral_questions[[i]]$AskingMember,
      function(x) ifelse(is.null(x), NA, x)))

    member_df$question_id <- oral_questions[[i]]$Id

    oral_questions[[i]]$AskingMember <- NULL 
  } else {

    member_df2 <- data.frame(lapply(
      oral_questions[[i]]$AskingMember,
      function(x) ifelse(is.null(x), NA, x)))

    member_df2$question_id <- oral_questions[[i]]$Id
    member_df <- rbind(member_df, member_df2)

    oral_questions[[i]]$AskingMember <- NULL
  }

 progress_perc(i, length(oral_questions), "MEMBERS:")


}

# Ministers answering

minister_df <- data.frame() # Initialise empty dataframe 

for (i in seq_along(oral_questions)) {
  if (is.null(oral_questions[[i]]$AnsweringMinister) == FALSE){
    
    if (nrow(minister_df) == 0) { # Check whether this is the first to have an answering minister

      minister_df <- data.frame(lapply(
        oral_questions[[i]]$AnsweringMinister,
        function(x) ifelse(is.null(x), NA, x)))

      minister_df$question_id <- oral_questions[[i]]$Id

      oral_questions[[i]]$AnsweringMinister <- NULL # Remove old sublist

    } else {

      minister_df2 <- data.frame(lapply(
        oral_questions[[i]]$AnsweringMinister,
        function(x) ifelse(is.null(x), NA, x)))

      minister_df2$question_id <- oral_questions[[i]]$Id

      minister_df <- rbind(minister_df, minister_df2)

      oral_questions[[i]]$AnsweringMinister <- NULL # Remove old sublist
    }

  } else {
    oral_questions[[i]][["AnsweringMinister"]] <- NULL
  }

 progress_perc(i, length(oral_questions), "MINISTERS:")

}

# Questions

for (i in seq_along(oral_questions)) {
  if (i == 1){
    question_df <- data.frame(lapply(
      oral_questions[[i]],
      function(x) ifelse(is.null(x), NA, x)))
  } else {
    question_df2 <- data.frame(lapply(
      oral_questions[[i]],
      function(x) ifelse(is.null(x), NA, x)))

    question_df <- rbind(question_df, question_df2)
  }

 progress_perc(i, length(oral_questions), "QUESTIONS:")

}

rm(member_df2, minister_df2, question_df2, i)

### Clean dataframes and merge into one table ####

question_df <- question_df %>%
  select(
    question_id = Id,
    question_short_text = QuestionText,
    question_status = Status,
    question_tabled_when = TabledWhen,
    question_answering_when = AnsweringWhen,
    question_answering_body_id = AnsweringBodyId)

minister_df <- minister_df %>%
  select(
    question_id,
    minister_Mnis_ID = MnisId
    )

member_df <- member_df %>%
  select(
    question_id,
    member_asking_Mnis_ID = MnisId)


question_table_main <- 
  left_join(question_df, member_df, by = "question_id")

question_table_main <- 
  left_join(question_table_main, minister_df, by = "question_id")
```

```{r}

dbWriteTable(db, "oral_questions", question_table_main, overwrite = TRUE)
db_table_check(db, "oral_questions")

```


```{r}
questions <- dbGetQuery(db, 
  "
  SELECT *
  FROM oral_questions

  LIMIT 100
  "
  )

glimpse(questions)
```

Many MP characteristics change over time - such as the party they represent, the ministerial posts they hold, etc. Therefore, we have to construct a members table that accomodates these changes. The UK Parliament members API allows queries that specifiy a date. This will give us a unique response that is valid on the day of each question. I will write out this "summarised" version of the data to my database. Then in analysis, I can query the entry that is valid for when each question is asked 

```{r pull-members-endpoint}

pull_members <- function(base_url, df) {

  cat("\n")
  print(paste0("Started at ", Sys.time()))
  cat("\n")

  pb <- txtProgressBar(min = 0, max = nrow(df), style = 3)
  
  for (i in seq_along(df$member_asking_Mnis_ID)) {

    url <- paste0(base_url, "/", df$member_asking_Mnis_ID[i], "?detailsForDate=", df$question_tabled_when[i]) 

    if (i == 1) {

      response <- GET(url) %>%
        content("parsed")
      response <- response[1]
      response <- c(date = df$question_tabled_when[i], response[[1]])

      response <- list(response)

    } else {
      response_new <- GET(url) %>% content("parsed")
      response_new <- response_new[1]
      response_new <- c(date = df$question_tabled_when[i], response_new[[1]])

      response_new <- list(response_new)

      response <- c(response, response_new) # Merge responses
    }

    Sys.sleep(0.5)

    setTxtProgressBar(pb, i)


  }

  cat("\n")
  print(paste0("Done at ", Sys.time(), " :))"))
  
  return(response)
}

# Connect to database

db <- DBI::dbConnect(RSQLite::SQLite(), here("data/parliament_database.sqlite"))

# Query the question database for the date the question was tables and who asked it 
questions <- dbGetQuery(db, 
  "
  SELECT member_asking_Mnis_ID, question_tabled_when
  FROM oral_questions
  "
)

questions <- unique(questions) # Avoid pulling the same queries by considering unique MP-date combinations

questions <- questions %>%
  mutate(question_tabled_when = str_extract(question_tabled_when, ".+?(?=T)"))

members <- pull_members("https://members-api.parliament.uk/api/Members", questions)

saveRDS(members, "data/members_raw.Rds")

members <-  lapply(members, function(lst) {lapply(lst, replace_null_with_na)})

for (i in seq_along(members)) {

  if (i == 1) {

    members_df <- members[i] %>%
      unlist() %>%
      t() %>%
      data.frame()

  } else {
    members_df_new <- members[i] %>%
      unlist() %>%
      t() %>%
      data.frame()

    members_df <- rbind(members_df, members_df_new)
  }
}

members_df <- members_df %>%
  select(
    member_date_valid = date, 
    member_Mnis_ID = id, 
    member_name_display = nameDisplayAs, 
    member_latest_party = latestParty.id,
    member_gender = gender, 
    member_latest_constituency = latestHouseMembership.membershipFromId,
    member_membership_start_date = latestHouseMembership.membershipStartDate, 
    member_membership_end_date = latestHouseMembership.membershipEndDate,
    member_membership_end_reason = latestHouseMembership.membershipEndReason,
    member_name_full = nameFullTitle,
    member_name_list = nameListAs
  )

members_df <- members_df %>%
  group_by( # Group by all variables apart from date
    member_Mnis_ID,
    member_name_display,
    member_latest_party,
    member_gender,
    member_latest_constituency,
    member_membership_start_date,
    member_membership_end_date,
    member_membership_end_reason,
    member_name_full,
    member_name_list
  ) %>%
  summarize( # Summarise earliest date this is valid for and latest. This gives us a range of vlaues where this combination is duplicated 
    member_date_valid_min = min(member_date_valid), 
    member_date_valid_max = max(member_date_valid)
  )

dbWriteTable(db, "members", members_df, overwrite = TRUE)
```


```{r}

db_table_check(db, "members")

```

```{r pull-constituency-endpoints}

MPs <- dbGetQuery(db,
  "
  SELECT * 
  FROM members 
  ")

constituencies <- MPs$member_latest_constituency %>% 
  unique()

constituencies <- 
  data.frame(
    constituency_id = constituencies
  ) %>%
  mutate(

    cons_name = NA, 
    cons_start_date = NA, 
    cons_end_date = NA,

    last_election_1_electorate = NA,
    last_election_1_turnout = NA,
    last_election_1_majority = NA, 
    last_election_1_result = NA, 
    last_election_1_winning_party = NA,
    last_election_1_election_ID = NA,
    last_election_1_electionDate = NA,
    last_election_1_isGeneralElection = NA,

    last_election_2_electorate = NA,
    last_election_2_turnout = NA,
    last_election_2_majority = NA, 
    last_election_2_result = NA, 
    last_election_2_winning_party = NA,
    last_election_2_election_ID = NA,
    last_election_2_electionDate = NA,
    last_election_2_isGeneralElection = NA,

    last_election_3_electorate = NA,
    last_election_3_turnout = NA,
    last_election_3_majority = NA, 
    last_election_3_result = NA, 
    last_election_3_winning_party = NA,
    last_election_3_election_ID = NA,
    last_election_3_electionDate = NA,
    last_election_3_isGeneralElection = NA,

    last_election_4_electorate = NA,
    last_election_4_turnout = NA,
    last_election_4_majority = NA, 
    last_election_4_result = NA, 
    last_election_4_winning_party = NA,
    last_election_4_election_ID = NA,
    last_election_4_electionDate = NA,
    last_election_4_isGeneralElection = NA,

    shapefile = NA
    )


### Basic details 

pull_const_info <- function(cons_id) {
  url <- paste0(
    "https://members-api.parliament.uk/api/Location/Constituency/",
    cons_id)

    basic_info <- httr::GET(url) %>%
    httr::content("parsed")

    return(basic_info)
}

pb <- txtProgressBar(min = 0, max = length(constituencies$constituency_id), style = 3)


print(paste0(Sys.time(), " | BASIC INFO ..."))
cat("\n")

for(i in seq_along(constituencies$constituency_id)) {
  response <- pull_const_info(constituencies$constituency_id[i])
  response <- response[[1]]

  constituencies$cons_name[i] <- response$name
  constituencies$cons_start_date[i] <- response$startDate
  constituencies$cons_end_date[i] <- ifelse(is.null(response$endDate), NA, response$endDate)

  Sys.sleep(0.5)
  setTxtProgressBar(pb, i)
}


#saveRDS(constituencies, "data/constituencies_raw_basic.Rds")

print(paste0(Sys.time(), " | BASIC INFO done."))
cat("\n")

### Shape file

# Define function

get_cons_shapefile <- function(cons_id) {
  url <- paste0(
    "https://members-api.parliament.uk/api/Location/Constituency/",
    cons_id,
    "/Geometry")

  shapefile <- httr::GET(url) %>%
    httr::content("parsed")

  return(shapefile)
}

# Execute function
pb <- txtProgressBar(min = 0, max = length(constituencies$constituency_id), style = 3)


print(paste0(Sys.time(), " | SHAPE FILES ..."))
cat("\n")

for(i in seq_along(constituencies$constituency_id)) {
  response <- get_cons_shapefile(constituencies$constituency_id[i])
  response <- response[[1]]

  constituencies$shapefile[i] <- response

  Sys.sleep(0.5)
  setTxtProgressBar(pb, i)
}

saveRDS(constituencies, "data/constituencies_raw_shapefiles.Rds")

print(paste0(Sys.time(), " | SHAPE FILES done."))
cat("\n")

### Election results


get_cons_election_results <- function(cons_id) {
  url <- paste0(
    "https://members-api.parliament.uk/api/Location/Constituency/",
    cons_id,
    "/ElectionResults")

  results <- httr::GET(url) %>%
    httr::content("parsed")

  return(results)
}


print(paste0(Sys.time(), " | ELECTIONS ..."))
cat("\n")

for (i in seq_along(constituencies$constituency_id)) {
  response <- get_cons_election_results(constituencies$constituency_id[i])
  response <- response[[1]]

  response <- lapply(response, function(lst) {lapply(lst, replace_null_with_na)})

  constituencies$last_election_1_electorate[i] <- response[[1]]$electorate
  constituencies$last_election_1_turnout[i] <- response[[1]]$turnout  
  constituencies$last_election_1_majority[i] <- response[[1]]$majority
  constituencies$last_election_1_result[i] <- response[[1]]$result
  # If no winner recorded, skip this and assign NA
  if(length(response[[1]]$winningParty) > 1) { # When there is content in the winning party sublist, the length will be greater than 1
    constituencies$last_election_1_winning_party[i] <- response[[1]]$winningParty$id
  } else {
     constituencies$last_election_1_winning_party[i] <- NA
  }
  constituencies$last_election_1_election_ID[i] = response[[1]]$electionId
  constituencies$last_election_1_electionDate[i] = response[[1]]$electionDate
  constituencies$last_election_1_isGeneralElection[i] = response[[1]]$isGeneralElection

  constituencies$last_election_2_electorate[i] <- response[[2]]$electorate
  constituencies$last_election_2_turnout[i] <- response[[2]]$turnout 
  constituencies$last_election_2_majority[i] <- response[[2]]$majority
  constituencies$last_election_2_result[i] <- response[[2]]$result
  # If no winner recorded, skip this and assign NA
  if(length(response[[2]]$winningParty) > 1) {
    constituencies$last_election_2_winning_party[i] <- response[[2]]$winningParty$id
  } else {
     constituencies$last_election_2_winning_party[i] <- NA
  }
  constituencies$last_election_2_election_ID[i] = response[[2]]$electionId
  constituencies$last_election_2_electionDate[i] = response[[2]]$electionDate
  constituencies$last_election_2_isGeneralElection[i] = response[[2]]$isGeneralElection

  constituencies$last_election_3_electorate[i] <- response[[3]]$electorate
  constituencies$last_election_3_turnout[i] <- response[[3]]$turnout  
  constituencies$last_election_3_majority[i] <- response[[3]]$majority
  constituencies$last_election_3_result[i] <- response[[3]]$result
  # If no winner recorded, skip this and assign NA
  if(length(response[[3]]$winningParty) > 1) {
    constituencies$last_election_3_winning_party[i] <- response[[3]]$winningParty$id
  } else {
     constituencies$last_election_3_winning_party[i] <- NA
  }
  constituencies$last_election_3_election_ID[i] = response[[3]]$electionId
  constituencies$last_election_3_electionDate[i] = response[[3]]$electionDate
  constituencies$last_election_3_isGeneralElection[i] = response[[3]]$isGeneralElection

  constituencies$last_election_4_electorate[i] <- response[[4]]$electorate
  constituencies$last_election_4_turnout[i] <- response[[4]]$turnout   
  constituencies$last_election_4_majority[i] <- response[[4]]$majority
  constituencies$last_election_4_result[i] <- response[[4]]$result
  # If no winner recorded, skip this and assign NA
  if(length(response[[4]]$winningParty) > 1) {
    constituencies$last_election_4_winning_party[i] <- response[[4]]$winningParty$id
  } else {
     constituencies$last_election_4_winning_party[i] <- NA
  }
  constituencies$last_election_4_election_ID[i] = response[[4]]$electionId
  constituencies$last_election_4_electionDate[i] = response[[4]]$electionDate
  constituencies$last_election_4_isGeneralElection[i] = response[[4]]$isGeneralElection

  Sys.sleep(0.5)
  
  print(paste0(i, " of ", nrow(constituencies), " done."))
}

saveRDS(constituencies, "data/constituencies_raw.Rds")


```

- Constituency characteristics
  - Previous electoral results 
  - Socio-demographic features of the constituency


Constituency info
- We will get the cosntituency ID from the members pull. We can pull:
  - Election results for each constituency over different elections 
  - Shape files (for plotting later)
- Would like to add 
  - Basic demographic information 
  - Economic indicators 
  - Health indicators 




I obtained more constituency information from the UK House of Commons Library Constituecy dashboard. This does not have an API, and contains dynamic elements, so I use selinum to scrape it. 

This process was somewhat complicated by the fact that the dashboard is contained within an "iframe". This allows a different html tree to be embedded within the main html of the webpage meaning any CSS paths do not point to the actual path of the webpage. Do do this, we need to identify the iframe and use `switchToFrame()` to identify elements on the dashboard. 

HOUSEPRICE INFO ONLY IN ENG AND WALES, that's why so many NAs

```{r selenium-scrape-hoc-dashboard}

cons <- readRDS("data/constituencies_raw.Rds") 

cons <- cons %>%
  select(constituency_id, cons_name) %>%
  unique() %>%
  mutate(
    region_nation_hoclib23 = NA,
    population_hoclib23 = NA,
    area_hoclib23 = NA,
    age_0_29_hoclib23 = NA,
    age_30_64_hoclib23 = NA,
    age_65_plus_hoclib23 = NA, 
    uc_claimants_hoclib23 = NA, 
    median_house_price_hoclib23 = NA
  )

rD <- rsDriver(browser=c("firefox"), verbose = F, port = netstat::free_port(random = TRUE), chromever = NULL) 
driver <- rD$client

selector_list <- list()

selector_list$search_dropdown <- "/html/body/div[1]/report-embed/div/div[1]/div/div/div/div/exploration-container/div/div/docking-container/div/div/div/div/exploration-host/div/div/exploration/div/explore-canvas/div/div[2]/div/div[2]/div[2]/visual-container-repeat/visual-container[1]/transform/div/div[3]/div/div/visual-modern/div/div/div[2]/div/i"

selector_list$search_box <- "/html/body/div[7]/div[1]/div/div[1]/input"


selector_list$search_result <- "/html/body/div[7]/div[1]/div/div[2]/div/div[1]/div/div/div[1]/div/span"

selector_list$region_nation <- "/html/body/div[1]/report-embed/div/div[1]/div/div/div/div/exploration-container/div/div/docking-container/div/div/div/div/exploration-host/div/div/exploration/div/explore-canvas/div/div[2]/div/div[2]/div[2]/visual-container-repeat/visual-container[2]/transform/div/div[3]/div/div/visual-modern/div/div/div/div[1]/div/div/div/div/div"

selector_list$population <- "/html/body/div[1]/report-embed/div/div[1]/div/div/div/div/exploration-container/div/div/docking-container/div/div/div/div/exploration-host/div/div/exploration/div/explore-canvas/div/div[2]/div/div[2]/div[2]/visual-container-repeat/visual-container[3]/transform/div/div[3]/div/div/visual-modern/div/div/div/p[2]/span"

selector_list$area <- "/html/body/div[1]/report-embed/div/div[1]/div/div/div/div/exploration-container/div/div/docking-container/div/div/div/div/exploration-host/div/div/exploration/div/explore-canvas/div/div[2]/div/div[2]/div[2]/visual-container-repeat/visual-container[5]/transform/div/div[3]/div/div/visual-modern/div/div/div/p[2]/span"

selector_list$age_0_29 <- "/html/body/div[1]/report-embed/div/div[1]/div/div/div/div/exploration-container/div/div/docking-container/div/div/div/div/exploration-host/div/div/exploration/div/explore-canvas/div/div[2]/div/div[2]/div[2]/visual-container-repeat/visual-container[11]/transform/div/div[3]/div/div/visual-modern/div/div/div/div[1]/div/div/div/div/div/div[1]"

selector_list$age_30_64 <- "/html/body/div[1]/report-embed/div/div[1]/div/div/div/div/exploration-container/div/div/docking-container/div/div/div/div/exploration-host/div/div/exploration/div/explore-canvas/div/div[2]/div/div[2]/div[2]/visual-container-repeat/visual-container[13]/transform/div/div[3]/div/div/visual-modern/div/div/div/div[1]/div/div/div/div/div/div[1]"

selector_list$age_65_plus <- "/html/body/div[1]/report-embed/div/div[1]/div/div/div/div/exploration-container/div/div/docking-container/div/div/div/div/exploration-host/div/div/exploration/div/explore-canvas/div/div[2]/div/div[2]/div[2]/visual-container-repeat/visual-container[15]/transform/div/div[3]/div/div/visual-modern/div/div/div/div[1]/div/div/div/div/div/div[1]"

selector_list$uc_claimants <- "/html/body/div[1]/report-embed/div/div[1]/div/div/div/div/exploration-container/div/div/docking-container/div/div/div/div/exploration-host/div/div/exploration/div/explore-canvas/div/div[2]/div/div[2]/div[2]/visual-container-repeat/visual-container[28]/transform/div/div[3]/div/div/visual-modern/div/div/div/div[1]/div/div/div/div/div[1]/div[1]"

selector_list$house_prices <- "/html/body/div[1]/report-embed/div/div[1]/div/div/div/div/exploration-container/div/div/docking-container/div/div/div/div/exploration-host/div/div/exploration/div/explore-canvas/div/div[2]/div/div[2]/div[2]/visual-container-repeat/visual-container[39]/transform/div/div[3]/div/div/visual-modern/div/div/div/div[1]/div/div/div/div/div[2]/div[1]"


#constituency_name <- cons$cons_name[16]
#wait_base = 1

constituency_dash_scraper <- function(constituency_name, wait_base = 1){
  #Sys.sleep(wait_base * 4)
  search_dropdown <- driver$findElement(using = "xpath", value = selector_list$search_dropdown)
  search_dropdown$clickElement()

  Sys.sleep(wait_base * 2)
  search_box <- driver$findElement(using = "xpath", value = selector_list$search_box)
  #search_box$clickElement()
  search_box$clearElement()
  search_box$sendKeysToElement(list(constituency_name))

  Sys.sleep(wait_base * 4)
  first_result <- driver$findElement(using = "xpath", value = selector_list$search_result)
  first_result$clickElement()

  # Extract text 
  
  # Set defaults as NA

  region_nation_text <- NA
  population_text <- NA
  area_text <- NA
  age_0_29_text <- NA
  age_30_64_text <- NA
  age_65_plus_text <- NA
  uc_claimants_text <- NA
  house_prices_text <- NA

  Sys.sleep(wait_base * 4)

  # Region or nation
  tryCatch({
  suppressMessages({ 
    region_nation <- driver$findElement(using = "xpath", value = selector_list$region_nation)
    region_nation_text <- region_nation$getElementText()[[1]]
    })
  }, error = function(e) {
    print(paste0("Log: NA assigned for REGION/NATION at iteration ", i))
  })


  # Population 
  tryCatch({
  suppressMessages({ 
    population <- driver$findElement(using = "xpath", value = selector_list$population)
    population_text <- population$getElementText()[[1]]
    })
  }, error = function(e) {
    print(paste0("Log: NA assigned for POPULATION at iteration ", i))
  })

  # Area in sq km
  tryCatch({
  suppressMessages({ 
    area <- driver$findElement(using = "xpath", value = selector_list$area)
    area_text <- area$getElementText()[[1]]
    })
  }, error = function(e) {
    print(paste0("Log: NA assigned for AREA at iteration ", i))
  })

  # Age composition 
  tryCatch({
  suppressMessages({
    age_0_29 <- driver$findElement(using = "xpath", value = selector_list$age_0_29)
    age_0_29_text <- age_0_29$getElementText()[[1]]
    })
  }, error = function(e) {
    print(paste0("Log: NA assigned for AGE 0-29 PLUS at iteration ", i))
  })

  tryCatch({
  suppressMessages({
    age_30_64 <- driver$findElement(using = "xpath", value = selector_list$age_30_64)
    age_30_64_text <- age_30_64$getElementText()[[1]]
    })
  }, error = function(e) {
    print(paste0("Log: NA assigned for AGE 30-64 PLUS at iteration ", i))
  })

  tryCatch({
  suppressMessages({
    age_65_plus <- driver$findElement(using = "xpath", value = selector_list$age_65_plus)
    age_65_plus_text <- age_65_plus$getElementText()[[1]]
    })
  }, error = function(e) {
    print(paste0("Log: NA assigned for AGE 64 PLUS at iteration ", i))
  })

  # Universal credit claimants 
  tryCatch({
  suppressMessages({
    uc_claimants <- driver$findElement(using = "xpath", value = selector_list$uc_claimants)
    uc_claimants_text <- uc_claimants$getElementText()[[1]]
    })
  }, error = function(e) {
    print(paste0("Log: NA assigned for UC CLAIMANTS at iteration ", i))
  })

  # House price

  tryCatch({
    suppressMessages({
      house_prices <- driver$findElement(using = "xpath", value = selector_list$house_prices)
      house_prices_text <- house_prices$getElementText()[[1]]
    })
  }, error = function(e) {
    print(paste0("Log: NA assigned for HOUSE PRICE at iteration ", i))
  })


  results = list(
    region_nation_text, 
    population_text, area_text, 
    age_0_29_text, age_30_64_text, age_65_plus_text,
    uc_claimants_text, house_prices_text)

  return(results)

}

# Navigate to home page outside of the loop
driver$deleteAllCookies()
driver$navigate("https://commonslibrary.parliament.uk/constituency-dashboard/")

Sys.sleep(1)

# Identify and switch to sub-page 
iframe <- driver$findElement(using = "xpath", value = "//iframe[@title='Constituency dashboard']")
driver$switchToFrame(iframe)
Sys.sleep(4)

start_from = 1 # Set the number to start from
for (i in start_from:length(cons$constituency_id)) {

  results <- constituency_dash_scraper(cons$cons_name[i], wait_base = 1)

    cons$region_nation_hoclib23[i] <- results[[1]]

    cons$population_hoclib23[i] <- results[[2]]

    cons$area_hoclib23[i] <- results[[3]]

    cons$age_0_29_hoclib23[i] <- results[[4]]
    cons$age_30_64_hoclib23[i] <- results[[5]]
    cons$age_65_plus_hoclib23[i] <- results[[6]]

    cons$uc_claimants_hoclib23[i] <- results[[7]]
    cons$median_house_price_hoclib23[i] <- results[[8]]

 # Cache results collected so far
  if(i == start_from){
    saveRDS(cons, paste0("data/cache_cons_at", i, ".Rds"))
  } else {
     saveRDS(cons, paste0("data/cache_cons_at", i, ".Rds"))
     file.remove(paste0("data/cache_cons_at", i-1, ".Rds")) # delete last cached object
  }
  

  Sys.sleep(1)

  print(paste0(i, " of ", nrow(cons), " done."))

}

driver$close()
rD$server$stop()
system("taskkill /im java.exe /f", intern=FALSE, ignore.stdout=FALSE)

saveRDS(cons, "data/hoc_library_scrape_raw.Rds")

```

```{r}
# Clean dashboard data

cons_hoc <- readRDS("data/hoc_library_scrape_raw.Rds")

# pop numeric 
cons_hoc$population_hoclib23 <- cons_hoc$population_hoclib23 %>%
  str_remove_all(",") %>%
  as.numeric()

# area numeric

cons_hoc$area_hoclib23 <- cons_hoc$area_hoclib23 %>%
  str_extract(".*(?=\\s*sq\\.\\s*km)") %>%
  str_remove_all(",") %>%
  as.numeric()


# age perc

cons_hoc$age_0_29_hoclib23 <- cons_hoc$age_0_29_hoclib23 %>%
  str_remove_all("%") %>%
  as.numeric()
cons_hoc$age_0_29_hoclib23 <- cons_hoc$age_0_29_hoclib23/100 # Convert to proportion 

cons_hoc$age_30_64_hoclib23 <- cons_hoc$age_30_64_hoclib23 %>%
  str_remove_all("%") %>%
  as.numeric()
cons_hoc$age_30_64_hoclib23 <- cons_hoc$age_30_64_hoclib23/100 # Convert to proportion 

cons_hoc$age_65_plus_hoclib23 <- cons_hoc$age_65_plus_hoclib23 %>%
  str_remove_all("%") %>%
  as.numeric()
cons_hoc$age_65_plus_hoclib23 <- cons_hoc$age_65_plus_hoclib23/100 # Convert to proportion 

# uc numeric

cons_hoc$uc_claimants_hoclib23 <- cons_hoc$uc_claimants_hoclib23 %>%
  str_remove_all(",") %>%
  as.numeric()

# house price numeric

cons_hoc$median_house_price_hoclib23 <- cons_hoc$median_house_price_hoclib23 %>%
  str_remove_all(",|£") %>%
  as.numeric()

```

```{r}

# read in data pulled from Parliament API 

cons_api <- readRDS("data/constituencies_raw.Rds")

# Merge 


cons_hoc <- cons_hoc %>%
  select(-cons_name)

cons <- left_join(cons_api, cons_hoc, by = "constituency_id")


# Write out to database 

dbWriteTable(db, "constituencies", cons, overwrite = TRUE)
```


```{r}
dbListTables(db)
db_table_check(db, "oral_questions")
db_table_check(db, "members")
db_table_check(db, "constituencies")
```

```{r, eval = TRUE}
# Disconnect from local database
DBI::dbDisconnect(db)
```


# Analysis 

## Measure topics 

```{r}
question_text <- dbGetQuery(
  db, 
  "
  SELECT question_id, question_short_text
  FROM oral_questions
  "
) 

# Measure 

# Initalise variables as FALSE
question_text$is_econ <- 0
question_text$is_health_welf <- 0

# clean question text 

question_text$question_short_text <- question_text$question_short_text %>%
    tolower() %>% # Convert to lower case
    tm::removePunctuation() # remove punctuation

# Define dictionaries 
# TODO: better define dictionaries
econ_dict <- 
  "econ*|inflat*|grow*|interest rate*|budget*|gdp|autumn statement*|financ*|chancellor"
health_welf_dict <- " nhs |universal credit| covid |pandemic*"

question_text <- question_text %>%
  mutate(
    is_econ = as.numeric(str_detect(question_short_text, econ_dict)), 
    is_health_welf = as.numeric(str_detect(question_short_text, health_welf_dict))
  )

 ``` 

```{r}

# Write out measured data to new table

question_text <- question_text %>% select(-question_short_text)

dbWriteTable(db, "question_topics", question_text, overwrite=TRUE)

```

## Descriptive analysis 

### Time 

```{r time-plot, eval = TRUE}

# Query database to return a table with the count of questions asked on each day 

time_data <- dbGetQuery(db, 
  "
  SELECT 
    oral_questions.question_tabled_when AS date_asked,
    SUM(question_topics.is_econ) AS econ_count,
    SUM(question_topics.is_health_welf) AS health_welf_count, 
    COUNT(*) AS total_question_count,
    SUM(question_topics.is_econ)/COUNT(*) AS econ_prop,
    SUM(question_topics.is_health_welf)/COUNT(*) AS health_welf_prop


  FROM oral_questions
    LEFT JOIN question_topics ON oral_questions.question_id = question_topics.question_id
  
  GROUP BY 
    oral_questions.question_tabled_when
  ")


time_data$date_asked <- as.Date(time_data$date_asked)
time_data$year <- format(time_data$date_asked, "%Y") 

plot <- time_data %>%
  ggplot(aes(x=date_asked)) +
  geom_col(aes(y=econ_count)) + 
  geom_smooth(aes(y=econ_count))

plot

```

### Geography

```{r geog-plot, eval = TRUE}

geog_data <- dbGetQuery(db, 
  "
  SELECT 
    constituencies.cons_name AS constituency, 
    
    SUM(question_topics.is_econ) AS econ_count,
    SUM(question_topics.is_health_welf) AS health_welf_count, 
    COUNT(*) AS total_question_count,
    SUM(question_topics.is_econ)/COUNT(*) AS econ_prop,
    SUM(question_topics.is_health_welf)/COUNT(*) AS health_welf_prop,
    
    constituencies.shapefile AS con_shapefile


  FROM oral_questions
    JOIN question_topics 
      ON oral_questions.question_id = question_topics.question_id
    JOIN members
      ON oral_questions.member_asking_Mnis_ID = members.member_Mnis_ID
        AND oral_questions.question_tabled_when BETWEEN members.member_date_valid_min AND members.member_date_valid_max
    JOIN constituencies 
      ON members.member_latest_constituency = constituencies.constituency_id
  
  GROUP BY constituencies.cons_name
  "
  )

# Plot base map
tm_shape(geog_data$con_shapefile) +
  tm_sf()



```



## Exploratory analysis 


```{r econ-tree}
# FIXME: check why filter BETWEEN reduces number returned 
## I think it might be because there are observations *after* the last change 

analysis_df_econ <- dbGetQuery(
  db, 
  "
  SELECT 
    question_topics.is_econ AS is_econ,

    members.member_latest_party,
    members.member_gender,
    constituencies.last_election_1_electorate,   
    constituencies.last_election_1_turnout,         
    constituencies.last_election_1_majority,               
    constituencies.last_election_1_isGeneralElection,              
    constituencies.region_nation_hoclib23,           
    constituencies.population_hoclib23,          
    constituencies.area_hoclib23,                   
    constituencies.age_0_29_hoclib23,            
    constituencies.age_30_64_hoclib23,               
    constituencies.age_65_plus_hoclib23,         
    constituencies.uc_claimants_hoclib23,            
    constituencies.median_house_price_hoclib23 

  FROM oral_questions
  JOIN question_topics
    ON oral_questions.question_id = question_topics.question_id
  JOIN members 
    ON oral_questions.member_asking_Mnis_ID = members.member_Mnis_ID
      AND oral_questions.question_tabled_when BETWEEN members.member_date_valid_min AND members.member_date_valid_max
  JOIN constituencies 
    ON members.member_latest_constituency = constituencies.constituency_id
  "
) %>%
  mutate(is_econ = factor(is_econ)) # TODO: check convert to factor works

# TODO: deal with missing values 

```

```{r}
#econ_last_fit <- readRDS("data/rf_econ_last_fit.Rds"))

# Variable importance plot

econ_vi_plot <- econ_last_fit %>%
  pluck(".workflow", 1) %>%
  extract_fit_parsnip() %>%
  vip(num_features = 10) + #  CANDO can vary this
  labs(title = "Variable importance for asking Economic Questions")

econ_vi_plot

```

# Code appendix
```{r, eval = TRUE}
sessionInfo()
```

```{r ref.label=knitr::all_labels(), echo=TRUE} 

```



